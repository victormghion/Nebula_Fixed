# ğŸš€ Nebula Agent v6.0 - Agente de Testes Inteligente

ParabÃ©ns! Seu **Nebula Agent** foi aprimorado para a versÃ£o **6.0**, com uma interface moderna e profissional (inspirada no Manus) e com a nova funcionalidade de **GeraÃ§Ã£o AutomÃ¡tica de CenÃ¡rios Gherkin** usando Machine Learning (simulado) e Large Language Models (LLM).

## âœ¨ Novidades da VersÃ£o 6.0

1.  **Interface Moderna (Inspirada no Manus):** Design mais limpo, profissional e responsivo, mantendo a identidade visual verde/ciano.
2.  **Agente de Testes (LLM-Powered):** A lÃ³gica de chat foi substituÃ­da por um agente inteligente focado em BDD (Behavior-Driven Development).
3.  **GeraÃ§Ã£o AutomÃ¡tica de Gherkin:** O agente gera cenÃ¡rios de teste completos em Gherkin (`Feature`, `Scenario`, `Given`, `When`, `Then`) com base na sua solicitaÃ§Ã£o e na **anÃ¡lise visual da tela**.
4.  **Arquitetura Preparada para ML:** A funÃ§Ã£o de **AnÃ¡lise Visual de Tela** estÃ¡ simulada (`simulate_screen_analysis` em `agent.py`), permitindo uma integraÃ§Ã£o futura com um modelo de VisÃ£o Computacional real.

## ğŸ› ï¸ Como Executar o Projeto

O projeto Ã© construÃ­do em **Python** com **FastAPI** para o backend e **HTML/CSS/JavaScript** para o frontend.

### PrÃ©-requisitos

*   Python 3.8+
*   Acesso Ã  internet para o LLM (OpenAI)

### 1. InstalaÃ§Ã£o de DependÃªncias

Certifique-se de estar no diretÃ³rio raiz do projeto (`nebula-agent`) e instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

### 2. ConfiguraÃ§Ã£o do LLM

O projeto utiliza um Large Language Model (LLM) para a geraÃ§Ã£o do Gherkin. Ele usa a biblioteca `openai` e espera que as credenciais sejam configuradas via variÃ¡veis de ambiente.

**Recomendado:** O sistema estÃ¡ configurado para usar um endpoint compatÃ­vel com OpenAI. VocÃª pode configurar a chave de API da seguinte forma:

```bash
# Substitua pela sua chave de API
export OPENAI_API_KEY="SUA_CHAVE_AQUI" 
```

### 3. InicializaÃ§Ã£o do Servidor

Inicie o servidor usando `uvicorn`:

```bash
uvicorn application:app --reload
```

O servidor serÃ¡ iniciado em `http://127.0.0.1:8000`.

## ğŸ’¡ Como Usar o Novo Agente

O agente foi treinado para responder a comandos de geraÃ§Ã£o de Gherkin.

1.  **Acesse:** Abra seu navegador em `http://127.0.0.1:8000`.
2.  **Comande:** PeÃ§a ao agente para gerar um cenÃ¡rio.

**Exemplos de Comandos:**

*   `Gerar um cenÃ¡rio Gherkin para o fluxo de login com sucesso`
*   `Criar um teste para o checkout de um produto`
*   `Quero o Gherkin para o cadastro de um novo usuÃ¡rio`

O agente irÃ¡:
1.  Interpretar sua intenÃ§Ã£o.
2.  Simular a anÃ¡lise visual da tela (ex: "Tela de Login com campos 'UsuÃ¡rio', 'Senha', botÃ£o 'Entrar'").
3.  Gerar o cenÃ¡rio Gherkin completo, formatado em um bloco de cÃ³digo Markdown.

## PrÃ³ximos Passos (IntegraÃ§Ã£o ML Real)

Para implementar a **anÃ¡lise visual de tela real**, vocÃª precisarÃ¡:

1.  **Desenvolver/Integrar um Modelo de VisÃ£o Computacional:** Um modelo que receba uma imagem (screenshot) e retorne uma descriÃ§Ã£o estruturada dos elementos da tela (campos, botÃµes, labels).
2.  **Atualizar `agent.py`:** Substituir a funÃ§Ã£o `simulate_screen_analysis` por uma chamada de API para o seu novo modelo de ML.

```python
# Exemplo de como ficaria a funÃ§Ã£o atualizada em agent.py (futuro)
def get_real_screen_analysis(screenshot_path: str) -> str:
    # 1. Enviar a imagem para o seu serviÃ§o de ML
    # 2. Receber a descriÃ§Ã£o estruturada
    # return "DescriÃ§Ã£o detalhada da tela gerada pelo ML"
    pass
```

O restante da arquitetura (LLM e Gherkin Generator) jÃ¡ estÃ¡ pronto para consumir essa nova entrada!

